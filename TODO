- Triangle primitive




- Framework for surface primitives to manage their splitting and micropolygons
  in a thread-safe way.
	- Should be generic enough for all surface primitives to use.
	- Perhaps define an API that primitives must expose, which the framework
	  can use.
	- Two kinds of splitting: splitting to reduce individual grid size,
	  and splitting that has to happen for tracing in the first place.
	  E.g. a character made of nurbs patches naturally splits into
	  the individual patches, which is different from the individual
	  patches splitting to limit diced grid size.  It might be good
	  to make a distinction between those in the API.
	- How can this relate to a bigger picture that handles, e.g.,
	  particles, curves, and volumes as well?

- Surface primitive API:
	- separate() -- separates out natural component primitives that
	                together make up the original.  Used on scene
	                loading to make sure everything can be handled
	                by the surface framework.
	- split() -- splits the primitive into multiple primitives that
	             together make up the original.  May be called on scene
	             loading, but is primarily for the tracing stages.
	- micro_estimate() -- given a target microelement size, estimates
	                      the number of microelements that would have to
	                      be generated to achieve it.
	- micro_generate() -- generates the MicroSurface
	- class MicroSurface -- the description that is actually directly
	                        ray-tested against.  Different API's can be
	                        added to allow surface primitives to seed it,
	                        but by default the input will likely be a
	                        grid.  The MicroSurface handles
	                        displacements, etc.

- Intersection data should include information about how to offset
  rays spawned from the intersection point to avoid self-intersections.
  It should be a small vector which is added to the ray origin for
  reflection and subtracted for transmission.

- Two-stage ray tracing, similar to the Rayes (not Reyes) paper
	- Assign each thread an object id to trace rays for.
		- Each thread needs its own ray cache, which gets merged with
		  the main RayInter structers after the tracing is complete.
		  How to manage those caches efficiently?  A maximum on the rays
		  traced by a thread at once, maybe?  Tracing the rays in
		  chunks?
	- Refactor data structures and API to pass around/duplicate minimal
	  data when handling ray reordering and ray tracing.
		- Do we really need the RayInter structure at all?  And if so,
		  why not make it more ubiquitous throughout the renderer?



- Migrate all render configuration data to Renderer

- Simple scene-description format

- Propagation of ray differentials on bounces

- Adaptive sampling scheme
	//- Calculate variance information per pixel
	- Reduce the Sampler's responsibilities, migrating pixel/sample
	  traversal to be the Integrator's responsibilitiy.
	- Implement adaptive sample traversal based on variance

- Simple material system (for testing purposes
  only, eventually replace with OSL)

- Refactor TimeBox template to use class methods for interpolation

- Multi-threaded rendering

- OSL integration

- More compact and/or faster top-level BVH:
	- More compact probably actually doesn't matter so much, given
	  the intended usage of Psychopath.  The top-level BVH is likely
	  to be relatively sparse anyway compared to most path tracers,
	  since it uses higher-order surface descriptions.  Focus on speed.
	- Four basic approaches to speeding up traversal:
		- Reducing the number of nodes traversed on average
		- Reducing the cost of testing against each node
		- Using SIMD to test multiple nodes at once
		- Improving cache coherency of traversal by better tree layout
	- Must be able to pause and resume traversal with minimal data per ray
	- QBVH is worth investigating, but it's unclear how to do efficient
	  resumes.
	- MSBVH is good to look at, especially if some primitives may be
	  very large and clog up the tree.  Also could just try to keep large
	  primitives higher in the tree.
	- Single Slab Hierarchy is very interesting, but it's unclear if
	  efficient resumes are possible.  Unless we actually keep the
	  entire BBoxes at each node, and only trace it like a SSH when
	  possible...?  Maybe generalize to marking specific BBox sides
	  as important.
	- Variable-child BVH could be interesting, with SIMD used where applicable.
	  Similar tricky resume issue as QBVH, though.
	- "Restart trail" approach for resuming might extend to higher 
	  branch factors, e.g. QBVH.
	- What performance impact does a fixed traversal order have?
	  Does the reduction in branching compensate for less efficient
	  traversal?  What is the most efficient fixed traversal order?
	  SAH-based?  Pre-randomized?
	  A fixed traversal order would make resumes trivial on almost
	  any tree structure.

//- Faster sorting of potential ray intersections
	//- Counting sort
		- Big benefit of counting sort is we automatically get the starting
		  indices in the potential intersections array for each object.
		- http://www.drdobbs.com/architecture-and-design/parallel-counting-sort/224700144
		- http://www.drdobbs.com/parallel/parallel-counting-sort-part-2/225900071

